{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T13:04:07.669768Z",
     "start_time": "2025-04-02T13:04:05.734579Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maraw/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T13:04:07.672075Z",
     "start_time": "2025-04-02T13:04:07.670617Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_molecular_data(smiles):\n",
    "    with open(f'molecule_properties/{smiles}.json', 'r') as handle:\n",
    "        d = json.load(handle)\n",
    "\n",
    "    # for charges, fukui_electrophilicity, fukui_nucleophilicity, fukui_radical\n",
    "    # it is a dict. take the min, max, mean of the values of the dict and make a new key/value pairs in the root \n",
    "    # of d\n",
    "    for key in ['charges', 'fukui_electrophilicity', 'fukui_nucleophilicity', 'fukui_radical']:\n",
    "        d[key + '_min'] = min(d[key].values())\n",
    "        d[key + '_max'] = max(d[key].values())\n",
    "        d[key + '_mean'] = sum(d[key].values()) / len(d[key].values())\n",
    "\n",
    "    d['dipole_x'] = d['dipole'][0]\n",
    "    d['dipole_y'] = d['dipole'][1]\n",
    "    d['dipole_z'] = d['dipole'][2]\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T13:04:07.677154Z",
     "start_time": "2025-04-02T13:04:07.672490Z"
    }
   },
   "outputs": [],
   "source": [
    "def molecular_features(smiles):\n",
    "    d = load_molecular_data(smiles)\n",
    "    # select only the keys for which we have float values\n",
    "    d = {k: v for k, v in d.items() if isinstance(v, float)}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T13:04:07.797665Z",
     "start_time": "2025-04-02T13:04:07.674623Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'molecule_properties/C_C=C_C.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmolecular_features\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mC_C=C_C\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[3], line 2\u001B[0m, in \u001B[0;36mmolecular_features\u001B[0;34m(smiles)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmolecular_features\u001B[39m(smiles):\n\u001B[0;32m----> 2\u001B[0m     d \u001B[38;5;241m=\u001B[39m \u001B[43mload_molecular_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43msmiles\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;66;03m# select only the keys for which we have float values\u001B[39;00m\n\u001B[1;32m      4\u001B[0m     d \u001B[38;5;241m=\u001B[39m {k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m d\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(v, \u001B[38;5;28mfloat\u001B[39m)}\n",
      "Cell \u001B[0;32mIn[2], line 2\u001B[0m, in \u001B[0;36mload_molecular_data\u001B[0;34m(smiles)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_molecular_data\u001B[39m(smiles):\n\u001B[0;32m----> 2\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmolecule_properties/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43msmiles\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.json\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m handle:\n\u001B[1;32m      3\u001B[0m         d \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mload(handle)\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;66;03m# for charges, fukui_electrophilicity, fukui_nucleophilicity, fukui_radical\u001B[39;00m\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;66;03m# it is a dict. take the min, max, mean of the values of the dict and make a new key/value pairs in the root \u001B[39;00m\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;66;03m# of d\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:310\u001B[0m, in \u001B[0;36m_modified_open\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n\u001B[1;32m    303\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[1;32m    304\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    305\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    306\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    307\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    308\u001B[0m     )\n\u001B[0;32m--> 310\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'molecule_properties/C_C=C_C.json'"
     ]
    }
   ],
   "source": [
    "molecular_features('C_C=C_C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T13:04:07.798981Z",
     "start_time": "2025-04-02T13:04:07.798906Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('processed_reactions/all_data_filtered.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "def is_within_deviation(actual_product, expected_product, deviation=0.10):\n",
    "    if expected_product == 0:\n",
    "        return actual_product == 0\n",
    "    return abs(actual_product - expected_product) / abs(expected_product) <= deviation\n",
    "\n",
    "\n",
    "for entry in data:\n",
    "    r1 = entry['r_values'].get('constant_1')\n",
    "    r2 = entry['r_values'].get('constant_2')\n",
    "    r_product = entry.get('r-product')\n",
    "    \n",
    "    if r_product is None:\n",
    "        entry['r-product_filter'] = False\n",
    "        continue\n",
    "    \n",
    "    actual_product = r1 * r2\n",
    "    \n",
    "    # Check for division by zero\n",
    "    if r_product == 0:\n",
    "        deviation = float('inf') if actual_product != 0 else 0\n",
    "    else:\n",
    "        deviation = abs(actual_product - r_product) / abs(r_product)\n",
    "    \n",
    "    if is_within_deviation(actual_product, r_product):\n",
    "        entry['r-product_filter'] = False\n",
    "    else:\n",
    "        entry['r-product_filter'] = True # reaction should be filtered out\n",
    "\n",
    "\n",
    "def filter_conf_intervals(row):\n",
    "    if 'conf_intervals' in row and 'constant_conf_1' in row['conf_intervals'] and 'constant_conf_2' in row['conf_intervals']:\n",
    "        conf_1 = row['conf_intervals']['constant_conf_1']\n",
    "        conf_2 = row['conf_intervals']['constant_conf_2']\n",
    "        \n",
    "        # Ensure 'r1' and 'r2' are correctly retrieved from the row\n",
    "        r1 = row.get('r_values', {}).get('constant_1')\n",
    "        r2 = row.get('r_values', {}).get('constant_2')\n",
    "        \n",
    "        if r1 is not None and r2 is not None and conf_1 is not None and conf_2 is not None:\n",
    "            # Filter condition: Confidence intervals should not be greater than the corresponding r-values\n",
    "            return (conf_1 <= 1 * r1) and (conf_2 <= 1 * r2)\n",
    "    \n",
    "    # If conditions are not met, return True by default, meaning the row will not be filtered out\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T13:04:07.800063Z",
     "start_time": "2025-04-02T13:04:07.799966Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert JSON data to DataFrame\n",
    "df_full = pd.DataFrame(data)\n",
    "\n",
    "print('Initial datapoints: ', len(df_full))\n",
    "df_full = df_full[df_full.apply(filter_conf_intervals, axis=1)]\n",
    "print('Datapoints after confidence filter:', len(df_full))\n",
    "\n",
    "# Separate the filtered data\n",
    "df_filtered = df_full[df_full['r-product_filter'] == False]\n",
    "print('Datapoints after r-product filter:', len(df_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-02T13:04:07.801176Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filtered['r1'] = df_filtered['r_values'].apply(lambda x: x['constant_1'] if isinstance(x, dict) and 'constant_1' in x else None)\n",
    "df_filtered['r2'] = df_filtered['r_values'].apply(lambda x: x['constant_2'] if isinstance(x, dict) and 'constant_2' in x else None)\n",
    "\n",
    "df_filtered.dropna(subset=['r1', 'r2', 'solvent', 'monomer1_s', 'monomer2_s', 'temperature', 'calculation_method', 'polymerization_type'], inplace=True)\n",
    "\n",
    "df_filtered.drop(columns=['r-product_filter', 'r_values', 'r-product', 'monomer1_data', 'monomer2_data', 'conf_intervals'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-02T13:04:07.802659Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filtered_flipped = []\n",
    "\n",
    "# create the same rows, but with flipped monomers, i.e. monomer1_s <-> monomer2_s, monomer1 <-> monomer2, and r1 <-> r2\n",
    "for index, row in df_filtered.iterrows():\n",
    "    flipped_row = row.copy()\n",
    "    flipped_row['monomer1_s'] = row['monomer2_s']\n",
    "    flipped_row['monomer2_s'] = row['monomer1_s']\n",
    "    flipped_row['monomer1'] = row['monomer2']\n",
    "    flipped_row['monomer2'] = row['monomer1']\n",
    "    flipped_row['r1'] = row['r2']\n",
    "    flipped_row['r2'] = row['r1']\n",
    "    df_filtered_flipped.append(flipped_row)\n",
    "\n",
    "df_filtered_flipped = pd.DataFrame(df_filtered_flipped)\n",
    "df_filtered_flipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-02T13:04:07.804033Z"
    }
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem.Descriptors import MolLogP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-02T13:04:07.805338Z"
    }
   },
   "outputs": [],
   "source": [
    "# now, add the features for each monomer by loading the corresponding JSON file with `molecular_features` based on the monomer{i}_s column\n",
    "def add_molecular_features(df): \n",
    "    new_rows = []\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            monomer1_s = row['monomer1_s']\n",
    "            monomer2_s = row['monomer2_s']\n",
    "            monomer1 = row['monomer1']\n",
    "            monomer2 = row['monomer2']\n",
    "            temperature = row['temperature']\n",
    "            solvent = row['solvent']\n",
    "            calculation_method = row['calculation_method']\n",
    "            polymerization_method = row['polymerization_type']\n",
    "            solvent_logp = MolLogP(Chem.MolFromSmiles(solvent))\n",
    "\n",
    "            monomer1_data = molecular_features(monomer1_s)\n",
    "            monomer2_data = molecular_features(monomer2_s)\n",
    "            \n",
    "            # add _1 to the keys of monomer1_data and _2 to the keys of monomer2_data\n",
    "            monomer1_data = {f'{k}_1': v for k, v in monomer1_data.items()}\n",
    "            monomer2_data = {f'{k}_2': v for k, v in monomer2_data.items()}\n",
    "\n",
    "            # now, create new dict with all the data \n",
    "            new_row = {**row, **monomer1_data, **monomer2_data, 'temperature': temperature, 'solvent': solvent, 'calculation_method': calculation_method, 'polymerization_method': polymerization_method, 'solvent_logp': solvent_logp}\n",
    "\n",
    "            new_rows.append(new_row)\n",
    "        except FileNotFoundError as e: \n",
    "            print(f\"File not found: {e}\")\n",
    "    return pd.DataFrame(new_rows) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-02T13:04:07.806077Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filtered = add_molecular_features(df_filtered)\n",
    "df_filtered_flipped = add_molecular_features(df_filtered_flipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-02T13:04:07.806658Z"
    }
   },
   "outputs": [],
   "source": [
    "len(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-02T13:04:07.807299Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-02T13:04:07.807970Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "for train_idx, test_idx in KFold(n_splits=10).split(df_filtered):\n",
    "    train = df_filtered.iloc[train_idx]\n",
    "    test = df_filtered.iloc[test_idx]\n",
    "    \n",
    "    train_flipped = df_filtered_flipped.iloc[train_idx]\n",
    "    test_flipped = df_filtered_flipped.iloc[test_idx]\n",
    "    train = pd.concat([train, train_flipped])\n",
    "    test = pd.concat([test, test_flipped])\n",
    "\n",
    "    train['r1r2'] = train['r1'] * train['r2']\n",
    "    test['r1r2'] = test['r1'] * test['r2']\n",
    "\n",
    "    # Separate numerical and categorical features\n",
    "    numerical_features = ['temperature', \n",
    "       'ip_corrected_1', 'ea_1', 'homo_1', 'lumo_1',\n",
    "       'global_electrophilicity_1', 'global_nucleophilicity_1',\n",
    "       'best_conformer_energy_1', 'charges_min_1', 'charges_max_1',\n",
    "       'charges_mean_1', 'fukui_electrophilicity_min_1',\n",
    "       'fukui_electrophilicity_max_1', 'fukui_electrophilicity_mean_1',\n",
    "       'fukui_nucleophilicity_min_1', 'fukui_nucleophilicity_max_1',\n",
    "       'fukui_nucleophilicity_mean_1', 'fukui_radical_min_1',\n",
    "       'fukui_radical_max_1', 'fukui_radical_mean_1', 'dipole_x_1',\n",
    "       'dipole_y_1', 'dipole_z_1',  'ip_corrected_2', 'ea_2', 'homo_2',\n",
    "       'lumo_2', 'global_electrophilicity_2', 'global_nucleophilicity_2',  'charges_min_2', 'charges_max_2',\n",
    "       'charges_mean_2', 'fukui_electrophilicity_min_2',\n",
    "       'fukui_electrophilicity_max_2', 'fukui_electrophilicity_mean_2',\n",
    "       'fukui_nucleophilicity_min_2', 'fukui_nucleophilicity_max_2',\n",
    "       'fukui_nucleophilicity_mean_2', 'fukui_radical_min_2',\n",
    "       'fukui_radical_max_2', 'fukui_radical_mean_2', 'dipole_x_2',\n",
    "       'dipole_y_2', 'dipole_z_2', 'solvent_logp']\n",
    "    \n",
    "    categorical_features = ['temperature_unit', 'solvent', 'calculation_method', 'polymerization_type', 'polymerization_method']\n",
    "  \n",
    "    # Use column transformation\n",
    "    transformer = ColumnTransformer([\n",
    "        ('numerical', StandardScaler(), numerical_features),\n",
    "        ('categorical', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "    \n",
    "    # Fit the transformer to the train data\n",
    "    transformer.fit(train)\n",
    "    \n",
    "    # Transform the train and test data\n",
    "    train_transformed = transformer.transform(train)\n",
    "    test_transformed = transformer.transform(test)\n",
    "    \n",
    "    feature_names = transformer.get_feature_names_out()\n",
    "    label = 'r1r2'\n",
    "\n",
    "    # power transform the label\n",
    "    pt = PowerTransformer(method='yeo-johnson')\n",
    "    pt.fit(train[label].values.reshape(-1, 1))\n",
    "\n",
    "    train[label] = pt.transform(train[label].values.reshape(-1, 1))\n",
    "    test[label] = pt.transform(test[label].values.reshape(-1, 1))\n",
    "    \n",
    "    model = HistGradientBoostingRegressor()\n",
    "    model.fit(train_transformed, train[label])\n",
    "    y_pred = model.predict(test_transformed)\n",
    "    mse = mean_squared_error(test[label], y_pred)\n",
    "    r2 = r2_score(test[label], y_pred)\n",
    "    print(f\"MSE: {mse}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-02T13:04:07.808615Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "copolextractor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
